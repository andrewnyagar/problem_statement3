{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82a501d0-a8bf-48b4-afbf-cf141bbb8d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib \n",
    "matplotlib.rcParams[\"figure.figsize\"] = (20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "563e058c-327d-4de3-a5dc-57362ddd311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf834ebb-afa0-41c6-acce-0e943358b92d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'bengaluru_house_prices.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbengaluru_house_prices.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m df1\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bengaluru_house_prices.csv'"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"bengaluru_house_prices.csv\")\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bb439a-fb91-43a2-95fc-05a593c45316",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d71c836-97b5-45bf-b095-41c4f45c601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7779177-1c45-44eb-96e1-2ec06457984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop features that are not required to build our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea416d54-001c-4b6b-a687-a190f0ec4746",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.drop(['area_type','society','balcony','availability'],axis='columns')\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a753ac-72e6-425d-84cf-6fddc074dedc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Begin data Cleaning\n",
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce232bdf-e954-4bdb-a394-b1cd53abc554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle missing values: drop all missing values\n",
    "df3 = df2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cb6420-084c-4ad1-b13e-54c306af0494",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be17d059-cfe8-4a2e-ab5b-454d3473a533",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645a4f7a-464c-4213-be6c-e8619fa72d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to split raw values: create a new column bedrooms\n",
    "# size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f473bd73-41c8-4434-ae2d-240c36e46a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refine size column \n",
    "df3['bedrooms'] = df3['size'].apply(lambda x: int(x.split(' ')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bb7d77-6bca-4364-b213-1e1cf06b145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b096f9-bc13-4fa8-8483-33de21957a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next we examine the total_sqft feature: make its values in a single unit\n",
    "df3.total_sqft.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b8505a-8636-479b-8c57-99868d39fd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check total variations in the column\n",
    "def is_float(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except (TypeError, ValueError):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75634f90-b805-442e-852b-4e139c9614e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_object(1384-232)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75c36c5-39c2-488b-8121-bd6c8b6f6a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  return sqft values that are not float \n",
    "df_non_float = df3[df3['total_sqft'].apply(lambda x: isinstance(is_float(x), str))]\n",
    "df_non_float['total_sqft'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da51ea72-7793-4224-827a-860aa23a551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sqft_to_num(x):\n",
    "    tokens = x.split('-')\n",
    "    if len(tokens) == 2:\n",
    "        return (float(tokens[0])+float(tokens[1]))/2\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return None   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcdd7a2-d36f-4899-af39-c3a88f8c9269",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.copy()\n",
    "df4.total_sqft = df4.total_sqft.apply(convert_sqft_to_num)\n",
    "df4 = df4[df4.total_sqft.notnull()]\n",
    "df4.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2907c8-19c1-453e-a748-e51682d6ab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee278123-bfad-468d-8305-e6a8c72e16cf",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "add new feature price per square feet: an important variable real estate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f554b42b-f466-4fe2-a991-6c70152a2d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.copy()\n",
    "df5['price_per_sqft'] = df5['price']*100000/df5['total_sqft']\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035c27b8-a1f3-49f8-bf58-669c5a6ab9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df5.location.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd80dd25-e071-4955-8748-c748266f55b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_stats = df5.groupby('location')['location'].agg('count').sort_values(ascending=False)\n",
    "location_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd48823b-3458-4892-85c5-98acd76f65e4",
   "metadata": {},
   "source": [
    "## Examine variables.\n",
    "We need to apply dimensionality reduction technique here to reduce number of locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e781a590-b69a-4b9a-8d99-a892f91eee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_stats = df5['location'].value_counts(ascending=False)\n",
    "location_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef41c8a4-80e9-4a71-a85b-eaa91b2d178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(location_stats[location_stats<10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5990f22b-e90d-470b-bd03-c476e5d083de",
   "metadata": {},
   "source": [
    "Any location having less than 10 data points should be tagged as \"other\" location. This way number of categories can be reduced by huge amount. Later on when we do one hot encoding, it will help us with having fewer dummy columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc711fbe-182f-409b-9254-87775c1747dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "location_stats_less_than_10 = location_stats[location_stats<=10]\n",
    "location_stats_less_than_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef7fdad-dd22-4397-b118-3ea0997f9fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['location'] = df5['location'].apply(lambda x: \"other\" if x in location_stats_less_than_10 else x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a09d2a-be12-43fa-acfe-512ec159f133",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.location.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f805edae-1c81-4f09-a326-413f278ae291",
   "metadata": {},
   "source": [
    "## Outlier Detection and removal : using mean and standard deviation\n",
    "Data scienties typically have conversations business managers (who will have expertise in a given field). In real estate, they might tell the analyst the avg. square ft per bedroom figure, say 300 (i.e. 2 bhk apartment is minimum 600 sqft. If the dataset has records with 400 sqft apartment having 2 bedrooms then that can be removed as an outlier. In the following we will utilize 300 as our minimun\n",
    "<!-- df5.price_per_sqft.describe() -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d574b02e-6d12-4aaa-9bd6-cd2d7b02d5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5[df5.total_sqft/df5.bedrooms<300].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937a75de-5390-424b-adc3-a704b011b810",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df5[~(df5.total_sqft/df5.bedrooms<300)]\n",
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b0245b-37df-4372-99f3-1d712f22981d",
   "metadata": {},
   "source": [
    "In our next analysis, we find that min price per sqft is 267 rs/sqft whereas max is 12000000, this shows a wide variation in property prices. Thus, we remove outliers per location using mean and one standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f557d0b3-cc92-4869-bb00-a220de08798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pps_outliers(df):\n",
    "    df_out = pd.DataFrame()\n",
    "    for key, subdf in df.groupby('location'):\n",
    "        m = np.mean(subdf.price_per_sqft)\n",
    "        st = np.std(subdf.price_per_sqft)\n",
    "        reduced_df = subdf[(subdf.price_per_sqft>(m-st)) & (subdf.price_per_sqft<=(m+st))]\n",
    "        df_out = pd.concat([df_out,reduced_df],ignore_index=True)\n",
    "    return df_out\n",
    "df7 = remove_pps_outliers(df6)\n",
    "df7.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4b76a1-f7d9-421c-a145-ee1b5598335b",
   "metadata": {},
   "source": [
    " for a given location how does the 2 bedroom and 3 bedroom property prices compare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29adb2b-3aa8-4345-b5c3-8318911a859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_chart(df,location):\n",
    "    bhk2 = df7[(df7.location==location) & (df7.bedrooms==2)]\n",
    "    bhk3 = df7[(df7.location==location) & (df7.bedrooms==3)]\n",
    "    matplotlib.rcParams['figure.figsize'] = (15,10)\n",
    "    plt.scatter(bhk2.total_sqft,bhk2.price,color='blue',label='2 BHK', s=50)\n",
    "    plt.scatter(bhk3.total_sqft,bhk3.price,marker='+', color='green',label='3 BHK', s=50)\n",
    "    plt.xlabel(\"Total Square Feet Area\")\n",
    "    plt.ylabel(\"Price (Lakh Indian Rupees)\")\n",
    "    plt.title(location)\n",
    "    plt.legend()\n",
    "    \n",
    "plot_scatter_chart(df7,\"Rajaji Nagar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a44a8f-cb7e-4ed2-9597-ead97b614432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# location b: Hebbal\n",
    "plot_scatter_chart(df7,\"Hebbal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cba3696-5383-479a-9463-b999451d63f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check distribution using histograms \n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"figure.figsize\"] = (20,10)\n",
    "plt.hist(df7.price_per_sqft,rwidth=0.8)\n",
    "plt.xlabel(\"Price Per Square Feet\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffecb47-e63f-40ab-8a3f-a04b711b16b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check bathroom distribution\n",
    "df7.bath.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7954abbd-5ac9-47b9-ae42-43d4a82ccfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df7.bath,rwidth=0.8)\n",
    "plt.xlabel(\"Number of bathrooms\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742aaeab-5407-4c0e-aafa-1e0389b289be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop non-contributing columns: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed3b75b-d8e1-457d-8491-1fbdc4505fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e350713-31c2-4c5c-a849-b45a2edf1264",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = df7.drop(['size','price_per_sqft'], axis =1)\n",
    "df8.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40db2bf-6b8a-4e03-b2cf-454b942c5067",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df9.head()\n",
    "dummies = pd.get_dummies(df8.location, columns='locations')\n",
    "converted_dummies = dummies.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dafbf78-255c-43e1-9280-d87b475acf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9 = pd.concat([df8,converted_dummies],axis='columns')\n",
    "df9.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4161f1c-38c9-406b-8922-e755d195d9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the location column \n",
    "df10 = df9.drop('location',axis=1)\n",
    "df10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d47889-af88-4022-9324-92fb758f44b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3900dec-507a-438f-98d3-03dbdf0a1393",
   "metadata": {},
   "source": [
    "## Data Preparation and Model Buiding\n",
    "\n",
    "We will use 4 regressor algorithms and select the best using GridsearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c196b8b6-90bc-466f-b3e0-c13e9326d7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split X and y variables \n",
    "X = df10.iloc[:, df10.columns != 'price']\n",
    "y = df10.iloc[:, df10.columns == 'price']\n",
    "# print(f\"X {X} and Y {y}\")\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496f3e2d-1ef6-45b2-9755-f655f07aebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "best_params = {\n",
    "    \"n_estimators\": 200,\n",
    "    \"max_depth\": 3,\n",
    "    \"learning_rate\": 0.2,\n",
    "    \"loss\": \"squared_error\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c7fa58-90ee-4093-b1e2-252b7299ec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56067a3-dada-43f5-aed2-b4515cf10b80",
   "metadata": {},
   "source": [
    "1. XGBoost Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b2befb-be3b-4dd3-8d3c-9ff1289f96e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGmodel = GradientBoostingRegressor(**best_params)\n",
    "XGmodel.fit(X_train, y_train)\n",
    "print(f\"First five House predictions: {XGmodel.predict(X_train.head())} and the Score: {XGmodel.score(X_test, y_test)}\")\n",
    "mse = mean_squared_error(y_test, XGmodel.predict(X_test))\n",
    "print(\"\\n The mean squared error (MSE) on test set: {:.4f}\".format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce2fd72-518a-450e-adea-0e1bd26c2560",
   "metadata": {},
   "source": [
    "2. LinearRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7655d6eb-5197-4b6a-ab68-4a6f031289b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "lr_clf = LinearRegression()\n",
    "lr_clf.fit(X_train,y_train)\n",
    "mse = mean_squared_error(y_test, lr_clf.predict(X_test))\n",
    "print(f\"First five House predictions: {lr_clf.predict(X_train.head())} and the Model Score is : {lr_clf.score(X_test, y_test)}\")\n",
    "print(\"\\nThe mean squared error (MSE) on test set: {:.4f}\".format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8205fefc-4a25-444a-af08-2d66b7fc4c7b",
   "metadata": {},
   "source": [
    "Using K-fold cross validation to measure accuracy of of the Regressor models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c396cd58-391d-45f6-b0f7-029179fd9af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = ShuffleSplit(n_splits=3, test_size=0.1, random_state=0)\n",
    "\n",
    "print (f\"Linear Regressor Cross-Val Score: {cross_val_score(lr_clf, X, y, cv=cv)}\")\n",
    "print (f\"Extreme Gradient Booster Regressor Cross-Val Score: {cross_val_score(XGmodel, X, y, cv=cv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38808064-182d-4f49-ae13-b10fd205ccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## From the Observations above, None of the Model could maintain 80 percent accuracy over 5 training iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa13037-ee6d-4e45-b5ad-9be8104b07b9",
   "metadata": {},
   "source": [
    "## Using GridSearch for Parameter tuning and Validation: \n",
    "We will also use RandomForest and Lasso Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c7eed6-8890-4058-8f40-f4d0ae88a606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15d0309-c1f4-4409-9504-8cabd0fdc65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_best_model_using_gridsearchcv(X, y):\n",
    "    algos = {\n",
    "        'LinearRegression': {\n",
    "            'model': LinearRegression(),\n",
    "            'params': {\n",
    "                'fit_intercept': [True, False],\n",
    "                'copy_X': [True, False]\n",
    "            }\n",
    "        },\n",
    "        'GradientBoosting': {\n",
    "            'model': GradientBoostingRegressor(),\n",
    "            'params': {\n",
    "                'n_estimators': [100, 200],\n",
    "                'learning_rate': [0.01, 0.1],\n",
    "                'max_depth': [3,5],\n",
    "           \n",
    "                'random_state': [42]\n",
    "            }\n",
    "        },\n",
    "        'XGBoost': {\n",
    "            'model': XGBRegressor(),\n",
    "            'params': {\n",
    "                'n_estimators': [100, 200],\n",
    "                'learning_rate': [0.01, 0.1, 0.2],\n",
    "                'max_depth': [3,5]\n",
    "            \n",
    "            }\n",
    "        },\n",
    "         'decision_tree': {\n",
    "            'model': DecisionTreeRegressor(),\n",
    "            'params': {\n",
    "                'splitter': ['best','random']\n",
    "            }},\n",
    "        'RandomForest': {\n",
    "            'model': RandomForestRegressor(),\n",
    "            'params': {\n",
    "                'n_estimators': [100, 500],\n",
    "                'max_depth': [None, 10, 20],\n",
    "                'min_samples_split': [2, 10],\n",
    "                'min_samples_leaf': [1, 4]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    scores = []\n",
    "    cv = ShuffleSplit(n_splits=3, test_size=0.2, random_state=0)\n",
    "    \n",
    "    for algo_name, config in algos.items():\n",
    "        gs = GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False, n_jobs=-1)\n",
    "        gs.fit(X, y)\n",
    "        scores.append({\n",
    "            'model': algo_name,\n",
    "            'best_score': gs.best_score_,\n",
    "            'best_params': gs.best_params_\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4884ccaa-7d87-47dd-a9d9-4c9bdc18be5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "   # Call the function\n",
    "results = find_best_model_using_gridsearchcv(X, y)\n",
    "    \n",
    "    # Print results\n",
    "results.sort_values(by='best_score', ascending =False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a4d061-f3b6-4975-b38a-de8ba14caf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(by='best_score', ascending =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356bbcbe-3c22-4641-bbb4-d46d9316e040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_price(location, sqft, bath, bedroom):\n",
    "    pass\n",
    "    #   # Encode 'location' using the same encoder\n",
    "    \n",
    "    # location_encoded = le.transform([location])[0]\n",
    "    #   # Create input features as numpy array\n",
    "    # features = pd.DataFrame({\n",
    "    #     'location': [location_encoded],  # Example: pass location as string\n",
    "    #     'total_sqft': [sqft],    # Example: pass total square feet as numerical value\n",
    "    #     'bath': [bath],          # Example: pass number of bathrooms as numerical value\n",
    "    #     'bedrooms': [bedroom]     # Example: pass number of bedrooms as numerical value\n",
    "    # })\n",
    "    \n",
    "    # # Assuming `model` is your trained XGBoost model\n",
    "    # predicted_price = XGmodel.predict(features)\n",
    "    \n",
    "    # return predicted_price[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f436b4-0d95-40d1-8df5-cb808a69733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# location = 'Richards Town'\n",
    "# sqft = 1500\n",
    "# bath = 2\n",
    "# bedrooms = 3\n",
    "# predicted_price = predict_price(location, sqft, bath, bedroom)\n",
    "# print(f\"Predicted price for the property: ${predicted_price:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2deb48d-efc8-46ed-844f-ae84539abce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2910c156-ac1f-4be1-a7b5-e33d5ad495a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
