{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82a501d0-a8bf-48b4-afbf-cf141bbb8d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib \n",
    "matplotlib.rcParams[\"figure.figsize\"] = (20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563e058c-327d-4de3-a5dc-57362ddd311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf834ebb-afa0-41c6-acce-0e943358b92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"bengaluru_house_prices.csv\")\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bb439a-fb91-43a2-95fc-05a593c45316",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d71c836-97b5-45bf-b095-41c4f45c601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7779177-1c45-44eb-96e1-2ec06457984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop features that are not required to build our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea416d54-001c-4b6b-a687-a190f0ec4746",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.drop(['area_type','society','balcony','availability'],axis='columns')\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a753ac-72e6-425d-84cf-6fddc074dedc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Begin data Cleaning\n",
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce232bdf-e954-4bdb-a394-b1cd53abc554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle missing values: drop all missing values\n",
    "df3 = df2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cb6420-084c-4ad1-b13e-54c306af0494",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be17d059-cfe8-4a2e-ab5b-454d3473a533",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645a4f7a-464c-4213-be6c-e8619fa72d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to split raw values: create a new column bedrooms\n",
    "# size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f473bd73-41c8-4434-ae2d-240c36e46a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refine size column \n",
    "df3['bedrooms'] = df3['size'].apply(lambda x: int(x.split(' ')[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bb7d77-6bca-4364-b213-1e1cf06b145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b096f9-bc13-4fa8-8483-33de21957a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next we examine the total_sqft feature: make its values in a single unit\n",
    "df3.total_sqft.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b8505a-8636-479b-8c57-99868d39fd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check total variations in the column\n",
    "def is_float(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except (TypeError, ValueError):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75634f90-b805-442e-852b-4e139c9614e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_object(1384-232)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75c36c5-39c2-488b-8121-bd6c8b6f6a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  return sqft values that are not float \n",
    "df_non_float = df3[df3['total_sqft'].apply(lambda x: isinstance(is_float(x), str))]\n",
    "df_non_float['total_sqft'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da51ea72-7793-4224-827a-860aa23a551b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sqft_to_num(x):\n",
    "    tokens = x.split('-')\n",
    "    if len(tokens) == 2:\n",
    "        return (float(tokens[0])+float(tokens[1]))/2\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return None   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcdd7a2-d36f-4899-af39-c3a88f8c9269",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.copy()\n",
    "df4.total_sqft = df4.total_sqft.apply(convert_sqft_to_num)\n",
    "df4 = df4[df4.total_sqft.notnull()]\n",
    "df4.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2907c8-19c1-453e-a748-e51682d6ab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee278123-bfad-468d-8305-e6a8c72e16cf",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "add new feature price per square feet: an important variable real estate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f554b42b-f466-4fe2-a991-6c70152a2d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.copy()\n",
    "df5['price_per_sqft'] = df5['price']*100000/df5['total_sqft']\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035c27b8-a1f3-49f8-bf58-669c5a6ab9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df5.location.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd80dd25-e071-4955-8748-c748266f55b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_stats = df5.groupby('location')['location'].agg('count').sort_values(ascending=False)\n",
    "location_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd48823b-3458-4892-85c5-98acd76f65e4",
   "metadata": {},
   "source": [
    "## Examine locations which is a categorical variable.\n",
    "We need to apply dimensionality reduction technique here to reduce number of locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e781a590-b69a-4b9a-8d99-a892f91eee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_stats = df5['location'].value_counts(ascending=False)\n",
    "location_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef41c8a4-80e9-4a71-a85b-eaa91b2d178b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(location_stats[location_stats<10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5990f22b-e90d-470b-bd03-c476e5d083de",
   "metadata": {},
   "source": [
    "Any location having less than 10 data points should be tagged as \"other\" location. This way number of categories can be reduced by huge amount. Later on when we do one hot encoding, it will help us with having fewer dummy columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc711fbe-182f-409b-9254-87775c1747dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "location_stats_less_than_10 = location_stats[location_stats<=10]\n",
    "location_stats_less_than_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef7fdad-dd22-4397-b118-3ea0997f9fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['location'] = df5['location'].apply(lambda x: \"other\" if x in location_stats_less_than_10 else x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a09d2a-be12-43fa-acfe-512ec159f133",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.location.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f805edae-1c81-4f09-a326-413f278ae291",
   "metadata": {},
   "source": [
    "## Outlier Detection and removal : using mean and standard deviation\n",
    "Data scienties typically have conversations business managers (who will have expertise in a given field). In real estate, they might tell the analyst the avg. square ft per bedroom figure, say 300 (i.e. 2 bhk apartment is minimum 600 sqft. If the dataset has records with 400 sqft apartment having 2 bedrooms then that can be removed as an outlier. In the following we will utilize 300 as our minimun\n",
    "<!-- df5.price_per_sqft.describe() -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d574b02e-6d12-4aaa-9bd6-cd2d7b02d5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5[df5.total_sqft/df5.bedrooms<300].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937a75de-5390-424b-adc3-a704b011b810",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df5[~(df5.total_sqft/df5.bedrooms<300)]\n",
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b0245b-37df-4372-99f3-1d712f22981d",
   "metadata": {},
   "source": [
    "In our next analysis, we find that min price per sqft is 267 rs/sqft whereas max is 12000000, this shows a wide variation in property prices. Thus, we remove outliers per location using mean and one standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f557d0b3-cc92-4869-bb00-a220de08798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pps_outliers(df):\n",
    "    df_out = pd.DataFrame()\n",
    "    for key, subdf in df.groupby('location'):\n",
    "        m = np.mean(subdf.price_per_sqft)\n",
    "        st = np.std(subdf.price_per_sqft)\n",
    "        reduced_df = subdf[(subdf.price_per_sqft>(m-st)) & (subdf.price_per_sqft<=(m+st))]\n",
    "        df_out = pd.concat([df_out,reduced_df],ignore_index=True)\n",
    "    return df_out\n",
    "df7 = remove_pps_outliers(df6)\n",
    "df7.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4b76a1-f7d9-421c-a145-ee1b5598335b",
   "metadata": {},
   "source": [
    " for a given location how does the 2 bedroom and 3 bedroom property prices compare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29adb2b-3aa8-4345-b5c3-8318911a859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_chart(df,location):\n",
    "    bhk2 = df7[(df7.location==location) & (df7.bedrooms==2)]\n",
    "    bhk3 = df7[(df7.location==location) & (df7.bedrooms==3)]\n",
    "    matplotlib.rcParams['figure.figsize'] = (15,10)\n",
    "    plt.scatter(bhk2.total_sqft,bhk2.price,color='blue',label='2 BHK', s=50)\n",
    "    plt.scatter(bhk3.total_sqft,bhk3.price,marker='+', color='green',label='3 BHK', s=50)\n",
    "    plt.xlabel(\"Total Square Feet Area\")\n",
    "    plt.ylabel(\"Price (Lakh Indian Rupees)\")\n",
    "    plt.title(location)\n",
    "    plt.legend()\n",
    "    \n",
    "plot_scatter_chart(df7,\"Rajaji Nagar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a44a8f-cb7e-4ed2-9597-ead97b614432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# location b: Hebbal\n",
    "plot_scatter_chart(df7,\"Hebbal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cba3696-5383-479a-9463-b999451d63f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check distribution using histograms \n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"figure.figsize\"] = (20,10)\n",
    "plt.hist(df7.price_per_sqft,rwidth=0.8)\n",
    "plt.xlabel(\"Price Per Square Feet\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffecb47-e63f-40ab-8a3f-a04b711b16b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check bathroom distribution\n",
    "df7.bath.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7954abbd-5ac9-47b9-ae42-43d4a82ccfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df7.bath,rwidth=0.8)\n",
    "plt.xlabel(\"Number of bathrooms\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742aaeab-5407-4c0e-aafa-1e0389b289be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop non-contributing columns: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed3b75b-d8e1-457d-8491-1fbdc4505fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e350713-31c2-4c5c-a849-b45a2edf1264",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = df7.drop(['size','price_per_sqft'], axis =1)\n",
    "df8.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f66bb3-36cb-489c-a199-6581494eb800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's encode the location variable \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df8.location = le.fit_transform(df8['location'])\n",
    "# df8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3900dec-507a-438f-98d3-03dbdf0a1393",
   "metadata": {},
   "source": [
    "## Data Preparation and Model Buiding\n",
    "\n",
    "We will use 4 regressor algorithms and select the best using GridsearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c196b8b6-90bc-466f-b3e0-c13e9326d7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split X and y variables \n",
    "X = df8.iloc[:, df8.columns != 'price']\n",
    "y = df8.iloc[:, df8.columns == 'price']\n",
    "# print(f\"X {X} and Y {y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496f3e2d-1ef6-45b2-9755-f655f07aebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "params = {\n",
    "    \"n_estimators\": 500,\n",
    "    \"max_depth\": 4,\n",
    "    \"min_samples_split\": 5,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"loss\": \"squared_error\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c7fa58-90ee-4093-b1e2-252b7299ec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56067a3-dada-43f5-aed2-b4515cf10b80",
   "metadata": {},
   "source": [
    "1. XGBoost Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b2befb-be3b-4dd3-8d3c-9ff1289f96e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGmodel = GradientBoostingRegressor(**params)\n",
    "XGmodel.fit(X_train, y_train)\n",
    "print(f\"First five House predictions: {XGmodel.predict(X_train.head())} and the Score: {XGmodel.score(X_test, y_test)}\")\n",
    "mse = mean_squared_error(y_test, XGmodel.predict(X_test))\n",
    "print(\"\\n The mean squared error (MSE) on test set: {:.4f}\".format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce2fd72-518a-450e-adea-0e1bd26c2560",
   "metadata": {},
   "source": [
    "2. LinearRegressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7655d6eb-5197-4b6a-ab68-4a6f031289b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr_clf = LinearRegression()\n",
    "lr_clf.fit(X_train,y_train)\n",
    "mse = mean_squared_error(y_test, lr_clf.predict(X_test))\n",
    "print(f\"First five House predictions: {lr_clf.predict(X_train.head())} and the Model Score is : {lr_clf.score(X_test, y_test)}\")\n",
    "print(\"\\nThe mean squared error (MSE) on test set: {:.4f}\".format(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8205fefc-4a25-444a-af08-2d66b7fc4c7b",
   "metadata": {},
   "source": [
    "Using K-fold cross validation to measure accuracy of of the Regressor models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c396cd58-391d-45f6-b0f7-029179fd9af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = ShuffleSplit(n_splits=3, test_size=0.1, random_state=0)\n",
    "\n",
    "print (f\"Linear Regressor Cross-Val Score: {cross_val_score(lr_clf, X, y, cv=cv)}\")\n",
    "print (f\"Extreme Gradient Booster Regressor Cross-Val Score: {cross_val_score(XGmodel, X, y, cv=cv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38808064-182d-4f49-ae13-b10fd205ccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## From the Observations above, None of the Model could maintain 80 percent accuracy over 5 training iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa13037-ee6d-4e45-b5ad-9be8104b07b9",
   "metadata": {},
   "source": [
    "## Using GridSearch for Parameter tuning and Validation: \n",
    "We will also use RandomForest and Lasso Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c7eed6-8890-4058-8f40-f4d0ae88a606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15d0309-c1f4-4409-9504-8cabd0fdc65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_best_model_using_gridsearchcv(X, y):\n",
    "    algos = {\n",
    "        'LinearRegression': {\n",
    "            'model': LinearRegression(),\n",
    "            'params': {\n",
    "                'fit_intercept': [True, False],\n",
    "                'copy_X': [True, False]\n",
    "            }\n",
    "        },\n",
    "        'GradientBoosting': {\n",
    "            'model': GradientBoostingRegressor(),\n",
    "            'params': {\n",
    "                'n_estimators': [100, 200],\n",
    "                'learning_rate': [0.01, 0.1],\n",
    "                'max_depth': [3,5],\n",
    "           \n",
    "                'random_state': [42]\n",
    "            }\n",
    "        },\n",
    "        'XGBoost': {\n",
    "            'model': XGBRegressor(),\n",
    "            'params': {\n",
    "                'n_estimators': [100, 200],\n",
    "                'learning_rate': [0.01, 0.1, 0.2],\n",
    "                'max_depth': [3,5]\n",
    "            \n",
    "            }\n",
    "        },\n",
    "        'RandomForest': {\n",
    "            'model': RandomForestRegressor(),\n",
    "            'params': {\n",
    "                'n_estimators': [100, 500],\n",
    "                'max_depth': [None, 10, 20],\n",
    "                'min_samples_split': [2, 10],\n",
    "                'min_samples_leaf': [1, 4],\n",
    "                'max_features': ['auto', 'sqrt', 'log2'],\n",
    "                'bootstrap': [True, False],\n",
    "                'random_state': [42]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    scores = []\n",
    "    cv = ShuffleSplit(n_splits=3, test_size=0.2, random_state=0)\n",
    "    \n",
    "    for algo_name, config in algos.items():\n",
    "        gs = GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False, n_jobs=-1)\n",
    "        gs.fit(X, y)\n",
    "        scores.append({\n",
    "            'model': algo_name,\n",
    "            'best_score': gs.best_score_,\n",
    "            'best_params': gs.best_params_\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4884ccaa-7d87-47dd-a9d9-4c9bdc18be5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "   # Call the function\n",
    "results = find_best_model_using_gridsearchcv(X, y)\n",
    "    \n",
    "    # Print results\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
